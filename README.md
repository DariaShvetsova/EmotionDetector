# Распознавание эмоций в реальном времени

Проект направлен на распознавание эмоций в реальном времени в видеопотоке  использованием библиотеки `deepface` и OpenCV.
Программа захватывает видео с камеры. идентифицирует лица, выделяет их в рамки и подписывает эмоцию, распознанную на лице. Негативные эмоции выделяются красным цветом, нейтральные или позитивные - зеленым. 

## Инструкции по запуску

Перед настройкой программы убедитесь, что в вашем компьютере функционирует веб-камера

### Настройка:

1. Клонируйте репозиторий с помощью команды 
`git clone https://github.com/DariaShvetsova/EmotionDetector.git`.

2. Зайдите в директорию, содержащую клонированный репозиторий  `cd EmotionDetector`.

3. установите необходимые зависимости:
   - вариант 1  `pip install -r requirements.txt`.
   - вариант 2:
     - `pip install deepface`
     - `pip install opencv-python`

4. Выполните код:
   
   - Запустите скрипт Python.
   - Вебкамера активируется и начнется распознавание эмоций в реальном времении.
   - Эмоции будут подписаны над рамками, в которых находятся идентифицированные лица.


5. Чтобы прекратить работу программы, нажмите Ctrl+C

# Описание решения

1. Импорт основных библиотек: импортируйте cv2 для захвата видео и обработки изображений, а также deepface для модели обнаружения эмоций.

2. Загрузка каскадного классификатора Хаара: используйте cv2.CascadeClassifier(), чтобы загрузить XML-файл для обнаружения лиц.

3. Инициализация захвата видео: используйте cv2.VideoCapture(), чтобы инициировать захват видео с веб-камеры по умолчанию.

4. Вход в бесконечный цикл обработки кадров.

5. Преобразование в оттенки серого: каждый кадр преобразуется  в оттенки серого с помощью cv2.cvtColor().

6. Обнаружение лиц: Обнаружение лиц в рамке в оттенках серого с помощью face_cascade.detectMultiScale().

7. Извлечение области лица: для каждого обнаруженного лица извлекается область интереса (ROI), содержащую лицо.

8. Предварительная обработка: подготовка изображения лица для обнаружения эмоций, используя встроенную функцию предварительной обработки из библиотеки deepface.

9. Распознавание эмоций: используется предварительно обученная модель обнаружения эмоций, предоставляемую библиотекой deepface, для прогнозирования эмоций.

10. Маркировка эмоций: сопоставляется прогнозируемый индекс эмоций с соответствующей меткой эмоции.

11. Визуальная аннотация: чертятся прямоугольники вокруг обнаруженных лиц и помечаются  предсказанными эмоциями с помощью cv2.rectangle() и cv2.putText().

12. Вывод на экран: представляет результирующий кадр с помеченной эмоцией, используя cv2.imshow().

13. Завершение цикла: если нажата клавиша «q», цикл завершается.


# Благодарность
Данный код основан на проекте https://github.com/ajitharunai/Facial-Emotion-Recognition-with-OpenCV-and-Deepface/
